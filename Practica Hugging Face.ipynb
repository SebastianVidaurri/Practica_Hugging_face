{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets #dasets de huggin face\n",
        "\n",
        "#IMPORTANTE trabajar con las librerias actualizadas o que sean compatibles con el codigo\n",
        "!pip install --upgrade datasets\n",
        "!pip install --upgrade transformers\n"
      ],
      "metadata": {
        "id": "eGIC8KynCZ4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "44879252-9994-4c79-9105-2dc402fddc0a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import transformers"
      ],
      "metadata": {
        "id": "EuKBWZVkDH2u"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#es el dataloader para descargar el datasets\n",
        "from datasets import load_dataset\n",
        "reviews = load_dataset('rotten_tomatoes')\n",
        "reviews"
      ],
      "metadata": {
        "id": "FMB_MHWgDb99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#¿como pasamos el dataset de huggin Face a pandas?\n",
        "df_train = reviews['train'].to_pandas()\n",
        "df_train"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "d8nUtxHUH_5A",
        "outputId": "535a930d-4ed1-4fc9-9ecc-4139c7fc2e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "0     the rock is destined to be the 21st century's ...      1\n",
              "1     the gorgeously elaborate continuation of \" the...      1\n",
              "2                        effective but too-tepid biopic      1\n",
              "3     if you sometimes like to go to the movies to h...      1\n",
              "4     emerges as something rare , an issue movie tha...      1\n",
              "...                                                 ...    ...\n",
              "8525  any enjoyment will be hinge from a personal th...      0\n",
              "8526  if legendary shlockmeister ed wood had ever ma...      0\n",
              "8527  hardly a nuanced portrait of a young woman's b...      0\n",
              "8528    interminably bleak , to say nothing of boring .      0\n",
              "8529  things really get weird , though not particula...      0\n",
              "\n",
              "[8530 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1fa8ec21-59d7-470c-a9ef-419ad71c7820\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the rock is destined to be the 21st century's ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>effective but too-tepid biopic</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>if you sometimes like to go to the movies to h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>emerges as something rare , an issue movie tha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8525</th>\n",
              "      <td>any enjoyment will be hinge from a personal th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8526</th>\n",
              "      <td>if legendary shlockmeister ed wood had ever ma...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8527</th>\n",
              "      <td>hardly a nuanced portrait of a young woman's b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8528</th>\n",
              "      <td>interminably bleak , to say nothing of boring .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8529</th>\n",
              "      <td>things really get weird , though not particula...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8530 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fa8ec21-59d7-470c-a9ef-419ad71c7820')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1fa8ec21-59d7-470c-a9ef-419ad71c7820 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1fa8ec21-59d7-470c-a9ef-419ad71c7820');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d37431d0-9158-4d3d-850b-9a051823011f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d37431d0-9158-4d3d-850b-9a051823011f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d37431d0-9158-4d3d-850b-9a051823011f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7845ef12-7e12-4f92-a8ca-9853ecff9e2e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7845ef12-7e12-4f92-a8ca-9853ecff9e2e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 8530,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8530,\n        \"samples\": [\n          \"it would take a complete moron to foul up a screen adaptation of oscar wilde's classic satire .\",\n          \"so we got ten little indians meets friday the 13th by way of clean and sober , filmed on the set of carpenter's the thing and loaded with actors you're most likely to find on the next inevitable incarnation of the love boat .\",\n          \"unfortunately , heartbreak hospital wants to convey the same kind of haughtiness in its own sketchy material but this territory has already been explored previously with better aplomb and sardonic wit .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "source": [
        "# @title score\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "df_train.groupby('score').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "-CBOzKAEbMmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PIPELINE es la manera principal de interactuar con los transformadores\n",
        "from transformers import pipeline\n",
        "#creamos un clasificador y ñe decimos que es un clasificador de sentimientos\n",
        "#dentro de pipeline podemos decirle que tipo de MODELO vamos a utilizar\n",
        "#en el ejemplo, como no especificamos el modelos, se utilizara no por defecto\n",
        "clasificador = pipeline('sentiment-analysis')\n",
        "clasificador('I love you')"
      ],
      "metadata": {
        "id": "i9Ad9NfQLdEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ejemplo de como aplicar el clasificador al dataset\n",
        "def score(review_text):\n",
        "  return clasificador(review_text)[0]['label']\n",
        "\n",
        "#aplicamos la funcion Score a la columna text y agregamos el resultado como una nueva columna\n",
        "df_train['score'] = df_train['text'].apply(score)\n",
        "df_train"
      ],
      "metadata": {
        "id": "JQXEhpclPNoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#para logearnos a huggin face desde la notebook\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "BpxgCQ3zEgm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NPL Pipelines"
      ],
      "metadata": {
        "id": "BdZpBWxlwa5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(pipeline)\n",
        "#las pipeline son sencillas de usar, eliges el modelo y la tarea que quieres que realize\n",
        "#con help vemos el listado de las posibles tareas que acepta pipeline\n"
      ],
      "metadata": {
        "id": "HU02pnZkwjna",
        "outputId": "bc7ed058-b4c1-41f3-b412-90a5fc948400",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function pipeline in module transformers.pipelines:\n",
            "\n",
            "pipeline(task: Optional[str] = None, model: Union[str, ForwardRef('PreTrainedModel'), ForwardRef('TFPreTrainedModel'), NoneType] = None, config: Union[str, transformers.configuration_utils.PretrainedConfig, NoneType] = None, tokenizer: Union[str, transformers.tokenization_utils.PreTrainedTokenizer, ForwardRef('PreTrainedTokenizerFast'), NoneType] = None, feature_extractor: Union[str, ForwardRef('SequenceFeatureExtractor'), NoneType] = None, image_processor: Union[str, transformers.image_processing_utils.BaseImageProcessor, NoneType] = None, processor: Union[str, transformers.processing_utils.ProcessorMixin, NoneType] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Union[str, bool, NoneType] = None, device: Union[int, str, ForwardRef('torch.device'), NoneType] = None, device_map=None, torch_dtype=None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[Dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs) -> transformers.pipelines.base.Pipeline\n",
            "    Utility factory method to build a [`Pipeline`].\n",
            "    \n",
            "    A pipeline consists of:\n",
            "    \n",
            "        - One or more components for pre-processing model inputs, such as a [tokenizer](tokenizer),\n",
            "        [image_processor](image_processor), [feature_extractor](feature_extractor), or [processor](processors).\n",
            "        - A [model](model) that generates predictions from the inputs.\n",
            "        - Optional post-processing steps to refine the model's output, which can also be handled by processors.\n",
            "    \n",
            "    <Tip>\n",
            "    While there are such optional arguments as `tokenizer`, `feature_extractor`, `image_processor`, and `processor`,\n",
            "    they shouldn't be specified all at once. If these components are not provided, `pipeline` will try to load\n",
            "    required ones automatically. In case you want to provide these components explicitly, please refer to a\n",
            "    specific pipeline in order to get more details regarding what components are required.\n",
            "    </Tip>\n",
            "    \n",
            "    Args:\n",
            "        task (`str`):\n",
            "            The task defining which pipeline will be returned. Currently accepted tasks are:\n",
            "    \n",
            "            - `\"audio-classification\"`: will return a [`AudioClassificationPipeline`].\n",
            "            - `\"automatic-speech-recognition\"`: will return a [`AutomaticSpeechRecognitionPipeline`].\n",
            "            - `\"depth-estimation\"`: will return a [`DepthEstimationPipeline`].\n",
            "            - `\"document-question-answering\"`: will return a [`DocumentQuestionAnsweringPipeline`].\n",
            "            - `\"feature-extraction\"`: will return a [`FeatureExtractionPipeline`].\n",
            "            - `\"fill-mask\"`: will return a [`FillMaskPipeline`]:.\n",
            "            - `\"image-classification\"`: will return a [`ImageClassificationPipeline`].\n",
            "            - `\"image-feature-extraction\"`: will return an [`ImageFeatureExtractionPipeline`].\n",
            "            - `\"image-segmentation\"`: will return a [`ImageSegmentationPipeline`].\n",
            "            - `\"image-text-to-text\"`: will return a [`ImageTextToTextPipeline`].\n",
            "            - `\"image-to-image\"`: will return a [`ImageToImagePipeline`].\n",
            "            - `\"image-to-text\"`: will return a [`ImageToTextPipeline`].\n",
            "            - `\"mask-generation\"`: will return a [`MaskGenerationPipeline`].\n",
            "            - `\"object-detection\"`: will return a [`ObjectDetectionPipeline`].\n",
            "            - `\"question-answering\"`: will return a [`QuestionAnsweringPipeline`].\n",
            "            - `\"summarization\"`: will return a [`SummarizationPipeline`].\n",
            "            - `\"table-question-answering\"`: will return a [`TableQuestionAnsweringPipeline`].\n",
            "            - `\"text2text-generation\"`: will return a [`Text2TextGenerationPipeline`].\n",
            "            - `\"text-classification\"` (alias `\"sentiment-analysis\"` available): will return a\n",
            "              [`TextClassificationPipeline`].\n",
            "            - `\"text-generation\"`: will return a [`TextGenerationPipeline`]:.\n",
            "            - `\"text-to-audio\"` (alias `\"text-to-speech\"` available): will return a [`TextToAudioPipeline`]:.\n",
            "            - `\"token-classification\"` (alias `\"ner\"` available): will return a [`TokenClassificationPipeline`].\n",
            "            - `\"translation\"`: will return a [`TranslationPipeline`].\n",
            "            - `\"translation_xx_to_yy\"`: will return a [`TranslationPipeline`].\n",
            "            - `\"video-classification\"`: will return a [`VideoClassificationPipeline`].\n",
            "            - `\"visual-question-answering\"`: will return a [`VisualQuestionAnsweringPipeline`].\n",
            "            - `\"zero-shot-classification\"`: will return a [`ZeroShotClassificationPipeline`].\n",
            "            - `\"zero-shot-image-classification\"`: will return a [`ZeroShotImageClassificationPipeline`].\n",
            "            - `\"zero-shot-audio-classification\"`: will return a [`ZeroShotAudioClassificationPipeline`].\n",
            "            - `\"zero-shot-object-detection\"`: will return a [`ZeroShotObjectDetectionPipeline`].\n",
            "    \n",
            "        model (`str` or [`PreTrainedModel`] or [`TFPreTrainedModel`], *optional*):\n",
            "            The model that will be used by the pipeline to make predictions. This can be a model identifier or an\n",
            "            actual instance of a pretrained model inheriting from [`PreTrainedModel`] (for PyTorch) or\n",
            "            [`TFPreTrainedModel`] (for TensorFlow).\n",
            "    \n",
            "            If not provided, the default for the `task` will be loaded.\n",
            "        config (`str` or [`PretrainedConfig`], *optional*):\n",
            "            The configuration that will be used by the pipeline to instantiate the model. This can be a model\n",
            "            identifier or an actual pretrained model configuration inheriting from [`PretrainedConfig`].\n",
            "    \n",
            "            If not provided, the default configuration file for the requested model will be used. That means that if\n",
            "            `model` is given, its default configuration will be used. However, if `model` is not supplied, this\n",
            "            `task`'s default model's config is used instead.\n",
            "        tokenizer (`str` or [`PreTrainedTokenizer`], *optional*):\n",
            "            The tokenizer that will be used by the pipeline to encode data for the model. This can be a model\n",
            "            identifier or an actual pretrained tokenizer inheriting from [`PreTrainedTokenizer`].\n",
            "    \n",
            "            If not provided, the default tokenizer for the given `model` will be loaded (if it is a string). If `model`\n",
            "            is not specified or not a string, then the default tokenizer for `config` is loaded (if it is a string).\n",
            "            However, if `config` is also not given or not a string, then the default tokenizer for the given `task`\n",
            "            will be loaded.\n",
            "        feature_extractor (`str` or [`PreTrainedFeatureExtractor`], *optional*):\n",
            "            The feature extractor that will be used by the pipeline to encode data for the model. This can be a model\n",
            "            identifier or an actual pretrained feature extractor inheriting from [`PreTrainedFeatureExtractor`].\n",
            "    \n",
            "            Feature extractors are used for non-NLP models, such as Speech or Vision models as well as multi-modal\n",
            "            models. Multi-modal models will also require a tokenizer to be passed.\n",
            "    \n",
            "            If not provided, the default feature extractor for the given `model` will be loaded (if it is a string). If\n",
            "            `model` is not specified or not a string, then the default feature extractor for `config` is loaded (if it\n",
            "            is a string). However, if `config` is also not given or not a string, then the default feature extractor\n",
            "            for the given `task` will be loaded.\n",
            "        image_processor (`str` or [`BaseImageProcessor`], *optional*):\n",
            "            The image processor that will be used by the pipeline to preprocess images for the model. This can be a\n",
            "            model identifier or an actual image processor inheriting from [`BaseImageProcessor`].\n",
            "    \n",
            "            Image processors are used for Vision models and multi-modal models that require image inputs. Multi-modal\n",
            "            models will also require a tokenizer to be passed.\n",
            "    \n",
            "            If not provided, the default image processor for the given `model` will be loaded (if it is a string). If\n",
            "            `model` is not specified or not a string, then the default image processor for `config` is loaded (if it is\n",
            "            a string).\n",
            "        processor (`str` or [`ProcessorMixin`], *optional*):\n",
            "            The processor that will be used by the pipeline to preprocess data for the model. This can be a model\n",
            "            identifier or an actual processor inheriting from [`ProcessorMixin`].\n",
            "    \n",
            "            Processors are used for multi-modal models that require multi-modal inputs, for example, a model that\n",
            "            requires both text and image inputs.\n",
            "    \n",
            "            If not provided, the default processor for the given `model` will be loaded (if it is a string). If `model`\n",
            "            is not specified or not a string, then the default processor for `config` is loaded (if it is a string).\n",
            "        framework (`str`, *optional*):\n",
            "            The framework to use, either `\"pt\"` for PyTorch or `\"tf\"` for TensorFlow. The specified framework must be\n",
            "            installed.\n",
            "    \n",
            "            If no framework is specified, will default to the one currently installed. If no framework is specified and\n",
            "            both frameworks are installed, will default to the framework of the `model`, or to PyTorch if no model is\n",
            "            provided.\n",
            "        revision (`str`, *optional*, defaults to `\"main\"`):\n",
            "            When passing a task name or a string model identifier: The specific model version to use. It can be a\n",
            "            branch name, a tag name, or a commit id, since we use a git-based system for storing models and other\n",
            "            artifacts on huggingface.co, so `revision` can be any identifier allowed by git.\n",
            "        use_fast (`bool`, *optional*, defaults to `True`):\n",
            "            Whether or not to use a Fast tokenizer if possible (a [`PreTrainedTokenizerFast`]).\n",
            "        use_auth_token (`str` or *bool*, *optional*):\n",
            "            The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n",
            "            when running `huggingface-cli login` (stored in `~/.huggingface`).\n",
            "        device (`int` or `str` or `torch.device`):\n",
            "            Defines the device (*e.g.*, `\"cpu\"`, `\"cuda:1\"`, `\"mps\"`, or a GPU ordinal rank like `1`) on which this\n",
            "            pipeline will be allocated.\n",
            "        device_map (`str` or `Dict[str, Union[int, str, torch.device]`, *optional*):\n",
            "            Sent directly as `model_kwargs` (just a simpler shortcut). When `accelerate` library is present, set\n",
            "            `device_map=\"auto\"` to compute the most optimized `device_map` automatically (see\n",
            "            [here](https://huggingface.co/docs/accelerate/main/en/package_reference/big_modeling#accelerate.cpu_offload)\n",
            "            for more information).\n",
            "    \n",
            "            <Tip warning={true}>\n",
            "    \n",
            "            Do not use `device_map` AND `device` at the same time as they will conflict\n",
            "    \n",
            "            </Tip>\n",
            "    \n",
            "        torch_dtype (`str` or `torch.dtype`, *optional*):\n",
            "            Sent directly as `model_kwargs` (just a simpler shortcut) to use the available precision for this model\n",
            "            (`torch.float16`, `torch.bfloat16`, ... or `\"auto\"`).\n",
            "        trust_remote_code (`bool`, *optional*, defaults to `False`):\n",
            "            Whether or not to allow for custom code defined on the Hub in their own modeling, configuration,\n",
            "            tokenization or even pipeline files. This option should only be set to `True` for repositories you trust\n",
            "            and in which you have read the code, as it will execute code present on the Hub on your local machine.\n",
            "        model_kwargs (`Dict[str, Any]`, *optional*):\n",
            "            Additional dictionary of keyword arguments passed along to the model's `from_pretrained(...,\n",
            "            **model_kwargs)` function.\n",
            "        kwargs (`Dict[str, Any]`, *optional*):\n",
            "            Additional keyword arguments passed along to the specific pipeline init (see the documentation for the\n",
            "            corresponding pipeline class for possible values).\n",
            "    \n",
            "    Returns:\n",
            "        [`Pipeline`]: A suitable pipeline for the task.\n",
            "    \n",
            "    Examples:\n",
            "    \n",
            "    ```python\n",
            "    >>> from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
            "    \n",
            "    >>> # Sentiment analysis pipeline\n",
            "    >>> analyzer = pipeline(\"sentiment-analysis\")\n",
            "    \n",
            "    >>> # Question answering pipeline, specifying the checkpoint identifier\n",
            "    >>> oracle = pipeline(\n",
            "    ...     \"question-answering\", model=\"distilbert/distilbert-base-cased-distilled-squad\", tokenizer=\"google-bert/bert-base-cased\"\n",
            "    ... )\n",
            "    \n",
            "    >>> # Named entity recognition pipeline, passing in a specific model and tokenizer\n",
            "    >>> model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
            "    >>> tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
            "    >>> recognizer = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
            "    ```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizacion"
      ],
      "metadata": {
        "id": "wNlG6t_tFmZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "#un AutoTokenaizer necesita leer un tokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "#los LLM tienen un tokenizador dentro de ellos"
      ],
      "metadata": {
        "id": "5B5kq21fwuNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tenemos un texto para tokenizar\n",
        "oracion = \"Preposterous, I'm flabbergasted!\"\n",
        "\n",
        "input_ids = tokenizer(oracion, return_tensors = 'pt').input_ids\n",
        "#Return_tensors = 'pt' quiere decir que el tokenizador debe devolver los token como tenzores de Torch\n",
        "\n",
        "input_ids\n",
        "\n",
        "#Palabra --> tokens --> ids unicos --> vertor embed\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlK1WC8ZHjV5",
        "outputId": "b952009d-6d7e-4caf-fe77-16a638250a0a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[37534,  6197,   516,    11,   314,  1101,   781,   397,  3900,  8992,\n",
              "             0]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "como convertimos los tokens a texto?"
      ],
      "metadata": {
        "id": "CO5V3Vy5NUsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(37534)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mR2_1cwoLDNN",
        "outputId": "2e39a6fb-d8ba-4451-c6c7-ca607f177124"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Prep'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token_id in input_ids[0]:\n",
        "  print(tokenizer.decode(token_id))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hTtSHTjMTJlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "si quisieramos un modelo para que complete la oracion"
      ],
      "metadata": {
        "id": "bd90qIksVYbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "#utilizamos AotuModel para no recordar cada modelo con su respectivo tokenizer\n",
        "\n",
        "gpt2 = AutoModelForCausalLM.from_pretrained('gpt2')\n",
        "texto = \"I skip across the\"\n",
        "input_ids = tokenizer(texto, return_tensors = 'pt').input_ids\n",
        "#Return_tensors = 'pt' quiere decir que el tokenizador debe devolver los token como tenzores de Torch\n",
        "\n",
        "input_ids\n",
        "\n",
        "#Palabra --> tokens --> ids unicos --> vertor embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUTHuWfKVMqP",
        "outputId": "9bc373be-770a-49cc-b928-3f90a2b8015a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   40, 14267,  1973,   262]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = gpt2(input_ids)\n",
        "outputs.logits.shape\n",
        "#logits es como un softmax\n",
        "#vamos a ver que torch.Size([1, 4, 50257])\n",
        "#1 es el número de lote que\n",
        "#4 es el número de tokens\n",
        "#50257 es el tmaño total del vocavulario gpt2\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K_xbKQiZDoi",
        "outputId": "a2cf6da0-d9b5-4a71-a09f-62f95063f11e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 50257])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bHMA0u-RaKlC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Te damos la bienvenida a Colab",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}